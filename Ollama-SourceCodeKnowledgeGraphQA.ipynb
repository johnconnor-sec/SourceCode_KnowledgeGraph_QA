{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set up OpenAI credentials\n",
    "# load_dotenv()\n",
    "\n",
    "# Set up Neo4j credentials\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "\n",
    "# Initialize Neo4j graph\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents: ['NOTES.md', 'main.go', 'main.go', 'to_pdf.go', 'to_pdf.go', 'to_pdf.go', 'cli.go', 'cli.go', 'cli.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags.go', 'flags.go', 'flags.go', 'flags.go', 'cli_test.go', 'cli_test.go', 'cli_test.go', 'vendor.go', 'vendor.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain_test.go', 'domain_test.go', 'patterns.go', 'patterns.go', 'patterns.go', 'sessions.go', 'sessions.go', 'sessions.go', 'contexts.go', 'contexts.go', 'contexts.go', 'sessions_test.go', 'sessions_test.go', 'sessions_test.go', 'contexts_test.go', 'contexts_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage.go', 'storage.go', 'db_test.go', 'db_test.go', 'db_test.go', 'db_test.go', 'patterns_test.go', 'db.go', 'db.go', 'db.go', 'db.go', 'models.go', 'models.go', 'models.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'chatter_test.go', 'chatter_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'vendors.go', 'vendors.go', 'vendors.go', 'vendors.go', 'patterns_loader.go', 'patterns_loader.go', 'patterns_loader.go', 'chatter.go', 'chatter.go', 'chatter.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'pull_request_template.md', 'anthropic.go', 'anthropic.go', 'anthropic.go', 'gemini.go', 'gemini.go', 'gemini.go', 'gemini.go', 'groq.go', 'groq.go', 'groq.go', 'openai.go', 'openai.go', 'openai.go', 'openai.go', 'dryrun.go', 'dryrun.go', 'dryrun.go', 'siliconcloud.go', 'siliconcloud.go', 'siliconcloud.go', 'openrouter.go', 'openrouter.go', 'openrouter.go', 'azure.go', 'azure.go', 'azure.go', 'ollama.go', 'ollama.go', 'ollama.go', 'user.md', 'user.md', 'user.md']\n",
      "Split documents for Language.PYTHON: 327 chunks\n",
      "Split documents for Language.JS: 328 chunks\n",
      "Split documents for Language.GO: 344 chunks\n",
      "Split documents for Language.HTML: 289 chunks\n",
      "Split documents for Language.MARKDOWN: 327 chunks\n",
      "Graph schema updated: Node properties:\n",
      "CodeChunk {language: STRING, name: STRING, content: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:CodeChunk)-[:SAME_LANGUAGE]->(:CodeChunk)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def load_source_code_to_graph(directory_path):\n",
    "    try:\n",
    "        # Load source code\n",
    "        loader = GenericLoader.from_filesystem(\n",
    "            directory_path,\n",
    "            glob=\"**/*\",\n",
    "            suffixes=[\".py\", \".js\", \".go\", \".md\", \".html\"],\n",
    "            exclude=[r\"^\\..*\"],  # Exclude .dot files and virtual environments\n",
    "            parser=LanguageParser()\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Explicitly set document names\n",
    "        for doc in documents:\n",
    "            if 'source' in doc.metadata:\n",
    "                doc.metadata['name'] = os.path.basename(doc.metadata['source'])\n",
    "            else:\n",
    "                doc.metadata['name'] = 'Unknown'\n",
    "        \n",
    "        print(f\"Loaded documents: {[doc.metadata.get('name', 'Unknown') for doc in documents]}\")\n",
    "                                                                                                                                                                       \n",
    "        # Split documents if they're too large                                                                                                                        \n",
    "        languages = [                                                                                                                                                 \n",
    "            Language.PYTHON,                                                                                                                                          \n",
    "            Language.JS,                                                                                                                                              \n",
    "            Language.GO,                                                                                                                                              \n",
    "            Language.HTML,                                                                                                                                            \n",
    "            Language.MARKDOWN                                                                                                                                         \n",
    "        ]                                                                                                                                                             \n",
    "                                                                                                                                                                      \n",
    "        for lang in languages:                                                                                                                                        \n",
    "            text_splitter = RecursiveCharacterTextSplitter.from_language(                                                                                             \n",
    "                language=lang,                                                                                                                                        \n",
    "                chunk_size=500,                                                                                                                                      \n",
    "                chunk_overlap=0                                                                                                                                       \n",
    "            )                                                                                                                                                         \n",
    "            split_docs = text_splitter.split_documents(documents)                                                                                                     \n",
    "            print(f\"Split documents for {lang}: {len(split_docs)} chunks\")                                                                                            \n",
    "                                                                                                                                                                      \n",
    "            # Populate Neo4j graph                                                                                                                                    \n",
    "            for doc in split_docs:                                                                                                                                    \n",
    "                query = \"\"\"                                                                                                                                           \n",
    "                MERGE (f:CodeChunk {name: $name})                                                                                                                     \n",
    "                SET f.content = $content, f.language = $language                                                                                                      \n",
    "                \"\"\"                                                                                                                                                   \n",
    "                graph.query(query, {                                                                                                                                  \n",
    "                    \"name\": doc.metadata.get('name', 'Unknown'),                                                                                                      \n",
    "                    \"content\": doc.page_content,                                                                                                                      \n",
    "                    \"language\": doc.metadata.get('language', 'Unknown')                                                                                               \n",
    "                })\n",
    "                                                                                                                                                                       \n",
    "        # Create relationships between code chunks                                                                                                                    \n",
    "        graph.query(\"\"\"                                                                                                                                               \n",
    "        MATCH (a:CodeChunk), (b:CodeChunk)                                                                                                                            \n",
    "        WHERE a <> b AND a.language = b.language                                                                                                                      \n",
    "        MERGE (a)-[:SAME_LANGUAGE]->(b)                                                                                                                               \n",
    "        \"\"\")                                                                                                                                                          \n",
    "                                                                                                                                                                       \n",
    "        # Refresh graph schema                                                                                                                                        \n",
    "        graph.refresh_schema()                                                                                                                                        \n",
    "        print(\"Graph schema updated:\", graph.schema)                                                                                                                  \n",
    "    except Exception as e:                                                                                                                                            \n",
    "        print(f\"Error loading source code: {str(e)}\")\n",
    "        # Consider logging the error or handling specific exceptions\n",
    "        raise\n",
    "                                                                                                                                                                       \n",
    " # Example usage                                                                                                                                                       \n",
    "directory_path = \"/path/to/your/codebase\"                                                                                                                             \n",
    "load_source_code_to_graph(directory_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qa_chain():\n",
    "    try:\n",
    "        # Ensure we have a valid graph schema\n",
    "        graph.refresh_schema()\n",
    "        if not graph.schema:\n",
    "            raise ValueError(\"Graph schema is empty. Make sure data has been loaded into the graph.\")\n",
    "\n",
    "        # Initialize the language model\n",
    "        llm = ChatOllama(model=\"llama3.1\", temperature=0)  # Changed from gpt-4o-mini to gpt-3.5-turbo\n",
    "\n",
    "        # Create a custom prompt template\n",
    "        CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "        You are an AI assistant that helps to convert natural language questions about a codebase into Cypher queries.\n",
    "        Use the following neo4j graph schema to generate Cypher queries:\n",
    "        {schema}\n",
    "\n",
    "        The graph contains CodeChunk nodes with properties: content, language, and name.\n",
    "        CodeChunks with the same language are connected by SAME_LANGUAGE relationships.\n",
    "\n",
    "        When searching for specific terms, use CONTAINS or =~ for partial matches.\n",
    "        Always return the content of the CodeChunk nodes in your queries.\n",
    "        Do not include the word 'cypher' in your query.\n",
    "\n",
    "        Human: {question} Use the codebase provided in the current context.\n",
    "        AI: Based on the given schema, here's a Cypher query to answer your question:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        cypher_prompt = PromptTemplate(\n",
    "            input_variables=[\"schema\", \"question\"],\n",
    "            template=CYPHER_GENERATION_TEMPLATE\n",
    "        )\n",
    "\n",
    "        # Create the GraphCypherQAChain\n",
    "        chain = GraphCypherQAChain.from_llm(\n",
    "            graph=graph,\n",
    "            cypher_llm=llm,\n",
    "            qa_llm=llm,\n",
    "            verbose=True,\n",
    "            cypher_prompt=cypher_prompt,\n",
    "            validate_cypher=True,\n",
    "            return_intermediate_steps=True,\n",
    "            return_direct=False,\n",
    "            allow_dangerous_requests=True\n",
    "        )\n",
    "\n",
    "        print(\"QA Chain setup successfully.\")\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up QA Chain: {str(e)}\")\n",
    "        raise  # Re-raise the exception instead of returning None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def answer_query(chain, query):\n",
    "    try:\n",
    "        response = chain.run(query)\n",
    "        \n",
    "        # print(\"Full response:\", response)  # Add this line for debugging\n",
    "        \n",
    "        if isinstance(response, dict) and 'intermediate_steps' in response:\n",
    "            cypher_query = response['intermediate_steps'][0]['query']\n",
    "            print(\"Generated Cypher query:\")\n",
    "            print(cypher_query)\n",
    "            \n",
    "            cypher_result = response['intermediate_steps'][0]['result']\n",
    "            print(\"Cypher query result:\")\n",
    "            print(cypher_result)\n",
    "            \n",
    "            if not cypher_result:\n",
    "                return \"No matching data found in the graph for this query.\"\n",
    "            \n",
    "            # Process the cypher_result to generate a meaningful answer\n",
    "            if isinstance(cypher_result, list) and len(cypher_result) > 0:\n",
    "                content = cypher_result[0].get('c.content', '')\n",
    "                if content:\n",
    "                    return f\"Found relevant content: {content[:200]}...\"\n",
    "                else:\n",
    "                    return \"No relevant content found in the matched nodes.\"\n",
    "            else:\n",
    "                return f\"Unexpected result format: {cypher_result}\"\n",
    "        \n",
    "        # If the response is a string, return it directly\n",
    "        if isinstance(response, str):\n",
    "            return response\n",
    "        \n",
    "        # If we reach here, we couldn't find a proper answer\n",
    "        return f\"Unable to generate an answer. Response structure: {type(response)}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in answer_query: {str(e)}\")\n",
    "        return f\"An error occurred while processing your query: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source code from: /home/sarah/Documents/AI_Code/fabric\n",
      "Loaded documents: ['NOTES.md', 'main.go', 'main.go', 'to_pdf.go', 'to_pdf.go', 'to_pdf.go', 'cli.go', 'cli.go', 'cli.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags.go', 'flags.go', 'flags.go', 'flags.go', 'cli_test.go', 'cli_test.go', 'cli_test.go', 'vendor.go', 'vendor.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain_test.go', 'domain_test.go', 'patterns.go', 'patterns.go', 'patterns.go', 'sessions.go', 'sessions.go', 'sessions.go', 'contexts.go', 'contexts.go', 'contexts.go', 'sessions_test.go', 'sessions_test.go', 'sessions_test.go', 'contexts_test.go', 'contexts_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage.go', 'storage.go', 'db_test.go', 'db_test.go', 'db_test.go', 'db_test.go', 'patterns_test.go', 'db.go', 'db.go', 'db.go', 'db.go', 'models.go', 'models.go', 'models.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'chatter_test.go', 'chatter_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'vendors.go', 'vendors.go', 'vendors.go', 'vendors.go', 'patterns_loader.go', 'patterns_loader.go', 'patterns_loader.go', 'chatter.go', 'chatter.go', 'chatter.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'pull_request_template.md', 'anthropic.go', 'anthropic.go', 'anthropic.go', 'gemini.go', 'gemini.go', 'gemini.go', 'gemini.go', 'groq.go', 'groq.go', 'groq.go', 'openai.go', 'openai.go', 'openai.go', 'openai.go', 'dryrun.go', 'dryrun.go', 'dryrun.go', 'siliconcloud.go', 'siliconcloud.go', 'siliconcloud.go', 'openrouter.go', 'openrouter.go', 'openrouter.go', 'azure.go', 'azure.go', 'azure.go', 'ollama.go', 'ollama.go', 'ollama.go', 'user.md', 'user.md', 'user.md']\n",
      "Split documents for Language.PYTHON: 327 chunks\n",
      "Split documents for Language.JS: 328 chunks\n",
      "Split documents for Language.GO: 344 chunks\n",
      "Split documents for Language.HTML: 289 chunks\n",
      "Split documents for Language.MARKDOWN: 327 chunks\n",
      "Graph schema updated: Node properties:\n",
      "CodeChunk {language: STRING, name: STRING, content: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:CodeChunk)-[:SAME_LANGUAGE]->(:CodeChunk)\n",
      "Loaded 43 code chunks into the graph.\n",
      "QA Chain setup successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (c1:CodeChunk {name: \"CLI package\"})\n",
      "OPTIONAL MATCH (c1)-[r:SAME_LANGUAGE]->(c2)\n",
      "RETURN c1.content AS content\n",
      "UNION\n",
      "MATCH (c3:CodeChunk {language: \"CLI package language\"})\n",
      "OPTIONAL MATCH (c3)-[r:SAME_LANGUAGE]->(c4)\n",
      "WHERE c3.name =~ 'main function'\n",
      "OR c3.name =~ 'function'\n",
      "RETURN c3.content AS content\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: I don't know the answer.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mI'm ready to help. What is the natural language question about the codebase that you'd like me to convert into a Cypher query?\u001b[0m\n",
      "Error in answer_query: Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'I': expected 'FOREACH', 'ALTER', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'MATCH', 'MERGE', 'NODETACH', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n",
      "\"I'm ready to help. What is the natural language question about the codebase that you'd like me to convert into a Cypher query?\"\n",
      " ^}\n",
      "Answer: An error occurred while processing your query: Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'I': expected 'FOREACH', 'ALTER', 'CALL', 'USING PERIODIC COMMIT', 'CREATE', 'LOAD CSV', 'START DATABASE', 'STOP DATABASE', 'DEALLOCATE', 'DELETE', 'DENY', 'DETACH', 'DROP', 'DRYRUN', 'FINISH', 'GRANT', 'INSERT', 'MATCH', 'MERGE', 'NODETACH', 'OPTIONAL', 'REALLOCATE', 'REMOVE', 'RENAME', 'RETURN', 'REVOKE', 'ENABLE SERVER', 'SET', 'SHOW', 'TERMINATE', 'UNWIND', 'USE' or 'WITH' (line 1, column 1 (offset: 0))\n",
      "\"I'm ready to help. What is the natural language question about the codebase that you'd like me to convert into a Cypher query?\"\n",
      " ^}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "MATCH (c1:CodeChunk {language: 'go'})\n",
      "WHERE c1.name =~ '.*cli package.*'\n",
      "RETURN c1.content\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: I don't know the answer.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "MATCH (c:CodeChunk)\n",
      "WHERE c.content =~ 'function|main|program'\n",
      "RETURN c.content\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: I don't know the answer.\n",
      "\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def main():\n",
    "    try:\n",
    "        print(f\"Loading source code from: {directory_path}\")\n",
    "        load_source_code_to_graph(directory_path)\n",
    "        \n",
    "        # Print some statistics about the loaded data\n",
    "        node_count = graph.query(\"MATCH (n:CodeChunk) RETURN count(n) as count\")[0]['count']\n",
    "        print(f\"Loaded {node_count} code chunks into the graph.\")\n",
    "\n",
    "        qa_chain = setup_qa_chain()\n",
    "\n",
    "        while True:\n",
    "            user_query = input(\"Ask a question about the code (or type 'exit' to quit): \")\n",
    "            if user_query.lower() == 'exit':\n",
    "                break\n",
    "            try:\n",
    "                answer = answer_query(qa_chain, user_query)\n",
    "                print(\"Answer:\", answer)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing the query: {str(e)}\")\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    print(\"Exiting the program.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-teacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
