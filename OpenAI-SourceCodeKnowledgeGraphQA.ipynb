{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set up OpenAI credentials\n",
    "load_dotenv()\n",
    "\n",
    "# Set up Neo4j credentials\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "\n",
    "# Initialize Neo4j graph\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents: ['NOTES.md', 'main.go', 'main.go', 'to_pdf.go', 'to_pdf.go', 'to_pdf.go', 'cli.go', 'cli.go', 'cli.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags.go', 'flags.go', 'flags.go', 'flags.go', 'cli_test.go', 'cli_test.go', 'cli_test.go', 'vendor.go', 'vendor.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain_test.go', 'domain_test.go', 'patterns.go', 'patterns.go', 'patterns.go', 'sessions.go', 'sessions.go', 'sessions.go', 'contexts.go', 'contexts.go', 'contexts.go', 'sessions_test.go', 'sessions_test.go', 'sessions_test.go', 'contexts_test.go', 'contexts_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage.go', 'storage.go', 'db_test.go', 'db_test.go', 'db_test.go', 'db_test.go', 'patterns_test.go', 'db.go', 'db.go', 'db.go', 'db.go', 'models.go', 'models.go', 'models.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'chatter_test.go', 'chatter_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'vendors.go', 'vendors.go', 'vendors.go', 'vendors.go', 'patterns_loader.go', 'patterns_loader.go', 'patterns_loader.go', 'chatter.go', 'chatter.go', 'chatter.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'pull_request_template.md', 'anthropic.go', 'anthropic.go', 'anthropic.go', 'gemini.go', 'gemini.go', 'gemini.go', 'gemini.go', 'groq.go', 'groq.go', 'groq.go', 'openai.go', 'openai.go', 'openai.go', 'openai.go', 'dryrun.go', 'dryrun.go', 'dryrun.go', 'siliconcloud.go', 'siliconcloud.go', 'siliconcloud.go', 'openrouter.go', 'openrouter.go', 'openrouter.go', 'azure.go', 'azure.go', 'azure.go', 'ollama.go', 'ollama.go', 'ollama.go', 'user.md', 'user.md', 'user.md']\n",
      "Split documents for Language.PYTHON: 220 chunks\n",
      "Split documents for Language.JS: 223 chunks\n",
      "Split documents for Language.GO: 228 chunks\n",
      "Split documents for Language.HTML: 217 chunks\n",
      "Split documents for Language.MARKDOWN: 220 chunks\n",
      "Graph schema updated: Node properties:\n",
      "CodeChunk {language: STRING, name: STRING, content: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:CodeChunk)-[:SAME_LANGUAGE]->(:CodeChunk)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def load_source_code_to_graph(directory_path):\n",
    "    try:\n",
    "        # Load source code\n",
    "        loader = GenericLoader.from_filesystem(\n",
    "            directory_path,\n",
    "            glob=\"**/*\",\n",
    "            suffixes=[\".py\", \".js\", \".go\", \".md\", \".html\"],\n",
    "            exclude=[r\"^\\..*\"],  # Exclude .dot files and virtual environments\n",
    "            parser=LanguageParser()\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Explicitly set document names\n",
    "        for doc in documents:\n",
    "            if 'source' in doc.metadata:\n",
    "                doc.metadata['name'] = os.path.basename(doc.metadata['source'])\n",
    "            else:\n",
    "                doc.metadata['name'] = 'Unknown'\n",
    "        \n",
    "        print(f\"Loaded documents: {[doc.metadata.get('name', 'Unknown') for doc in documents]}\")\n",
    "                                                                                                                                                                       \n",
    "        # Split documents if they're too large                                                                                                                        \n",
    "        languages = [                                                                                                                                                 \n",
    "            Language.PYTHON,                                                                                                                                          \n",
    "            Language.JS,                                                                                                                                              \n",
    "            Language.GO,                                                                                                                                              \n",
    "            Language.HTML,                                                                                                                                            \n",
    "            Language.MARKDOWN                                                                                                                                         \n",
    "        ]                                                                                                                                                             \n",
    "                                                                                                                                                                      \n",
    "        for lang in languages:                                                                                                                                        \n",
    "            text_splitter = RecursiveCharacterTextSplitter.from_language(                                                                                             \n",
    "                language=lang,                                                                                                                                        \n",
    "                chunk_size=1000,                                                                                                                                      \n",
    "                chunk_overlap=0                                                                                                                                       \n",
    "            )                                                                                                                                                         \n",
    "            split_docs = text_splitter.split_documents(documents)                                                                                                     \n",
    "            print(f\"Split documents for {lang}: {len(split_docs)} chunks\")                                                                                            \n",
    "                                                                                                                                                                      \n",
    "            # Populate Neo4j graph                                                                                                                                    \n",
    "            for doc in split_docs:                                                                                                                                    \n",
    "                query = \"\"\"                                                                                                                                           \n",
    "                MERGE (f:CodeChunk {name: $name})                                                                                                                     \n",
    "                SET f.content = $content, f.language = $language                                                                                                      \n",
    "                \"\"\"                                                                                                                                                   \n",
    "                graph.query(query, {                                                                                                                                  \n",
    "                    \"name\": doc.metadata.get('name', 'Unknown'),                                                                                                      \n",
    "                    \"content\": doc.page_content,                                                                                                                      \n",
    "                    \"language\": doc.metadata.get('language', 'Unknown')                                                                                               \n",
    "                })\n",
    "                                                                                                                                                                       \n",
    "        # Create relationships between code chunks                                                                                                                    \n",
    "        graph.query(\"\"\"                                                                                                                                               \n",
    "        MATCH (a:CodeChunk), (b:CodeChunk)                                                                                                                            \n",
    "        WHERE a <> b AND a.language = b.language                                                                                                                      \n",
    "        MERGE (a)-[:SAME_LANGUAGE]->(b)                                                                                                                               \n",
    "        \"\"\")                                                                                                                                                          \n",
    "                                                                                                                                                                       \n",
    "        # Refresh graph schema                                                                                                                                        \n",
    "        graph.refresh_schema()                                                                                                                                        \n",
    "        print(\"Graph schema updated:\", graph.schema)                                                                                                                  \n",
    "    except Exception as e:                                                                                                                                            \n",
    "        print(f\"Error loading source code: {str(e)}\")\n",
    "        # Consider logging the error or handling specific exceptions\n",
    "        raise\n",
    "                                                                                                                                                                       \n",
    " # Example usage                                                                                                                                                       \n",
    "directory_path = \"/path/to/your/codebase\"                                                                                                                             \n",
    "load_source_code_to_graph(directory_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qa_chain():\n",
    "    try:\n",
    "        # Ensure we have a valid graph schema\n",
    "        graph.refresh_schema()\n",
    "        if not graph.schema:\n",
    "            raise ValueError(\"Graph schema is empty. Make sure data has been loaded into the graph.\")\n",
    "\n",
    "        # Initialize the language model\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # Changed from gpt-4o-mini to gpt-3.5-turbo\n",
    "\n",
    "        # Create a custom prompt template\n",
    "        CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "        You are an AI assistant that helps to convert natural language questions about a codebase into Cypher queries.\n",
    "        Use the following neo4j graph schema to generate Cypher queries:\n",
    "        {schema}\n",
    "\n",
    "        The graph contains CodeChunk nodes with properties: content, language, and name.\n",
    "        CodeChunks with the same language are connected by SAME_LANGUAGE relationships.\n",
    "\n",
    "        When searching for specific terms, use CONTAINS or =~ for partial matches.\n",
    "        Always return the content of the CodeChunk nodes in your queries.\n",
    "        Do not include the word 'cypher' in your query.\n",
    "\n",
    "        Human: {question} Use the codebase provided in the current context.\n",
    "        AI: Based on the given schema, here's a Cypher query to answer your question:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        cypher_prompt = PromptTemplate(\n",
    "            input_variables=[\"schema\", \"question\"],\n",
    "            template=CYPHER_GENERATION_TEMPLATE\n",
    "        )\n",
    "\n",
    "        # Create the GraphCypherQAChain\n",
    "        chain = GraphCypherQAChain.from_llm(\n",
    "            graph=graph,\n",
    "            cypher_llm=llm,\n",
    "            qa_llm=llm,\n",
    "            verbose=True,\n",
    "            cypher_prompt=cypher_prompt,\n",
    "            validate_cypher=True,\n",
    "            return_intermediate_steps=True,\n",
    "            return_direct=False,\n",
    "            allow_dangerous_requests=True\n",
    "        )\n",
    "\n",
    "        print(\"QA Chain setup successfully.\")\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up QA Chain: {str(e)}\")\n",
    "        raise  # Re-raise the exception instead of returning None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def answer_query(chain, query):\n",
    "    try:\n",
    "        response = chain.run(query)\n",
    "        \n",
    "        # print(\"Full response:\", response)  # Add this line for debugging\n",
    "        \n",
    "        if isinstance(response, dict) and 'intermediate_steps' in response:\n",
    "            cypher_query = response['intermediate_steps'][0]['query']\n",
    "            print(\"Generated Cypher query:\")\n",
    "            print(cypher_query)\n",
    "            \n",
    "            cypher_result = response['intermediate_steps'][0]['result']\n",
    "            print(\"Cypher query result:\")\n",
    "            print(cypher_result)\n",
    "            \n",
    "            if not cypher_result:\n",
    "                return \"No matching data found in the graph for this query.\"\n",
    "            \n",
    "            # Process the cypher_result to generate a meaningful answer\n",
    "            if isinstance(cypher_result, list) and len(cypher_result) > 0:\n",
    "                content = cypher_result[0].get('c.content', '')\n",
    "                if content:\n",
    "                    return f\"Found relevant content: {content[:200]}...\"\n",
    "                else:\n",
    "                    return \"No relevant content found in the matched nodes.\"\n",
    "            else:\n",
    "                return f\"Unexpected result format: {cypher_result}\"\n",
    "        \n",
    "        # If the response is a string, return it directly\n",
    "        if isinstance(response, str):\n",
    "            return response\n",
    "        \n",
    "        # If we reach here, we couldn't find a proper answer\n",
    "        return f\"Unable to generate an answer. Response structure: {type(response)}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error in answer_query: {str(e)}\")\n",
    "        return f\"An error occurred while processing your query: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source code from: /home/sarah/Documents/AI_Code/fabric\n",
      "Loaded documents: ['NOTES.md', 'main.go', 'main.go', 'to_pdf.go', 'to_pdf.go', 'to_pdf.go', 'cli.go', 'cli.go', 'cli.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags_test.go', 'flags.go', 'flags.go', 'flags.go', 'flags.go', 'cli_test.go', 'cli_test.go', 'cli_test.go', 'vendor.go', 'vendor.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'youtube.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable_test.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'configurable.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain.go', 'domain_test.go', 'domain_test.go', 'patterns.go', 'patterns.go', 'patterns.go', 'sessions.go', 'sessions.go', 'sessions.go', 'contexts.go', 'contexts.go', 'contexts.go', 'sessions_test.go', 'sessions_test.go', 'sessions_test.go', 'contexts_test.go', 'contexts_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage_test.go', 'storage.go', 'storage.go', 'db_test.go', 'db_test.go', 'db_test.go', 'db_test.go', 'patterns_test.go', 'db.go', 'db.go', 'db.go', 'db.go', 'models.go', 'models.go', 'models.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'models_test.go', 'chatter_test.go', 'chatter_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'fabric_test.go', 'vendors.go', 'vendors.go', 'vendors.go', 'vendors.go', 'patterns_loader.go', 'patterns_loader.go', 'patterns_loader.go', 'chatter.go', 'chatter.go', 'chatter.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'fabric.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'vendors_test.go', 'pull_request_template.md', 'anthropic.go', 'anthropic.go', 'anthropic.go', 'gemini.go', 'gemini.go', 'gemini.go', 'gemini.go', 'groq.go', 'groq.go', 'groq.go', 'openai.go', 'openai.go', 'openai.go', 'openai.go', 'dryrun.go', 'dryrun.go', 'dryrun.go', 'siliconcloud.go', 'siliconcloud.go', 'siliconcloud.go', 'openrouter.go', 'openrouter.go', 'openrouter.go', 'azure.go', 'azure.go', 'azure.go', 'ollama.go', 'ollama.go', 'ollama.go', 'user.md', 'user.md', 'user.md']\n",
      "Split documents for Language.PYTHON: 220 chunks\n",
      "Split documents for Language.JS: 223 chunks\n",
      "Split documents for Language.GO: 228 chunks\n",
      "Split documents for Language.HTML: 217 chunks\n",
      "Split documents for Language.MARKDOWN: 220 chunks\n",
      "Graph schema updated: Node properties:\n",
      "CodeChunk {language: STRING, name: STRING, content: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:CodeChunk)-[:SAME_LANGUAGE]->(:CodeChunk)\n",
      "Loaded 43 code chunks into the graph.\n",
      "QA Chain setup successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316626/3021051654.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = chain.run(query)\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (c:CodeChunk)\n",
      "WHERE c.content CONTAINS 'function'\n",
      "RETURN c.content\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'c.content': '## TODO:\\n- Check if we need to read the system.md for every patterns when runnign the ListAllPatterns\\n- Context management seems more complex than the one in the original fabric. Probably needs some work (at least to make it clear how it works)\\n- models on command line: give as well vendor (like `--model openai/gpt-4o`). If the vendor is not given, get it by retrieving all possible models and searching from that.\\n- if user gives the ollama url on command line, we need to update/init an ollama vendor.\\n- The db should host only things related to access and storage in ~/.config/fabric\\n- The interaction part of the Setup function should be in the cli (and perhaps all the Setup)'}, {'c.content': 'package cli\\n\\nimport (\\n\\t\"fmt\"\\n\\t\"os\"\\n\\t\"path/filepath\"\\n\\t\"strconv\"\\n\\t\"strings\"\\n\\n\\t\"github.com/danielmiessler/fabric/core\"\\n\\t\"github.com/danielmiessler/fabric/db\"\\n)\\n\\n// Cli Controls the cli. It takes in the flags and runs the appropriate functions\\n// Code for: func Cli() (message string, err error) {\\n\\n// Code for: func Setup(db *db.Db, skipUpdatePatterns bool) (ret *core.Fabric, err error) {'}, {'c.content': 'package cli\\n\\nimport (\\n\\t\"bytes\"\\n\\t\"io\"\\n\\t\"os\"\\n\\t\"strings\"\\n\\t\"testing\"\\n\\n\\t\"github.com/danielmiessler/fabric/common\"\\n\\t\"github.com/stretchr/testify/assert\"\\n)\\n\\n// Code for: func TestInit(t *testing.T) {\\n\\n// Code for: func TestReadStdin(t *testing.T) {\\n\\n// ReadStdin function assuming it\\'s part of `cli` package\\n// Code for: func ReadStdin(reader io.ReadCloser) (string, error) {\\n\\n// Code for: func TestBuildChatOptions(t *testing.T) {\\n\\n// Code for: func TestBuildChatRequest(t *testing.T) {'}, {'c.content': 'package common\\n\\nimport (\\n\\t\"bytes\"\\n\\t\"os\"\\n\\t\"testing\"\\n\\n\\t\"github.com/stretchr/testify/assert\"\\n)\\n\\n// Code for: func TestConfigurable_AddSetting(t *testing.T) {\\n\\n// Code for: func TestConfigurable_Configure(t *testing.T) {\\n\\n// Code for: func TestConfigurable_Setup(t *testing.T) {\\n\\n// Code for: func TestSetting_IsValid(t *testing.T) {\\n\\n// Code for: func TestSetting_Configure(t *testing.T) {\\n\\n// Code for: func TestSetting_FillEnvFileContent(t *testing.T) {\\n\\n// Code for: func TestSetting_Print(t *testing.T) {\\n\\n// Code for: func TestSetupQuestion_Ask(t *testing.T) {\\n\\n// Code for: func TestSettings_IsConfigured(t *testing.T) {\\n\\n// Code for: func TestSettings_Configure(t *testing.T) {\\n\\n// Code for: func TestSettings_FillEnvFileContent(t *testing.T) {\\n\\n// captureOutput captures the output of a function call\\n// Code for: func captureOutput(f func()) string {\\n\\n// captureInput captures the input for a function call\\n// Code for: func captureInput(input string) func() {'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: The main functions of the codebase include managing the command line interface (CLI) through the `Cli` function, setting up the database with the `Setup` function, and handling input and output operations such as reading from standard input with the `ReadStdin` function. Additionally, it includes various test functions to ensure the functionality of configuration settings and their validation.\n",
      "\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def main():\n",
    "    try:\n",
    "        print(f\"Loading source code from: {directory_path}\")\n",
    "        load_source_code_to_graph(directory_path)\n",
    "        \n",
    "        # Print some statistics about the loaded data\n",
    "        node_count = graph.query(\"MATCH (n:CodeChunk) RETURN count(n) as count\")[0]['count']\n",
    "        print(f\"Loaded {node_count} code chunks into the graph.\")\n",
    "\n",
    "        qa_chain = setup_qa_chain()\n",
    "\n",
    "        while True:\n",
    "            user_query = input(\"Ask a question about the code (or type 'exit' to quit): \")\n",
    "            if user_query.lower() == 'exit':\n",
    "                break\n",
    "            try:\n",
    "                answer = answer_query(qa_chain, user_query)\n",
    "                print(\"Answer:\", answer)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing the query: {str(e)}\")\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    print(\"Exiting the program.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-teacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
